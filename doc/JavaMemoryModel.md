 [本文大部分摘自书籍《Java并发编程的艺术》](https://www.amazon.cn/dp/B012NDCEA0/ref=sr_1_1?s=books&ie=UTF8&qid=1523863156&sr=1-1&keywords=java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF)
 ### Java内存模型

 #### 并发编程模型的两个关键问题
&#8194;&#8194;线程之间**如何通信**及线程之间**如何同步**（这里的线程指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。在共享内存的并发模型中，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信，在消息传递的并发模型中，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。  
&#8194;&#8194;同步是指程序中用于控制不同线程间操作发生相对顺序的机制。在共享内存模型中，同步是显式进行的。程序员必须显示指定某个方式或字段代码需要在线程之间互斥进行。在消息传递的并发模型中，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。  
&#8194;&#8194;Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。在编写并发程序的过程中，若不理解隐式进行的线程之间的通信的工作机制，很可能遇到各种奇怪的内存可见性问题。
 
 #### Java内存模型的抽象结构
&#8194;&#8194;&#8194;&#8194;Java中，所有实例域、静态域和数组域都存储在堆内存中，堆内存在线程之间共享。局部变量、方法定义参数和异常处理器参数不会再线程之间共享，他们不会有内存可见性问题，也不受内存模型的影响。Java线程之间的通信由Java内存模型（JMM）控制，JMM决定一个线程对共享变量的写入合适对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的贝蒂内存，本地内存中存储了该线程以读、写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。Java内存模型的抽象结构图如下：
 ![Alt Java内存模型抽象结构](https://github.com/YuanLicc/concurrent-notes/blob/master/doc/images/JMMAbstractModel.png)
&#8194;&#8194;&#8194;&#8194;可以看出，线程A、线程B之间需要通信的话，必须经历两个步骤：
 
 - 线程A把本地内存A中更新过的共享变量刷新到主内存中去。 
 
 - 线程B到主内存中去读取线程A之前已更新过的共享变量。  
 
可看出，JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证。
 
 #### 指令序列重排序
 
&#8194;&#8194;&#8194;&#8194;在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序，分为三种：

 - 编译器优化的重排序  
    编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
 
 - 指令级并行的重排序。  
    现代处理器采用了指令级并行技术（ILP）来讲多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
 
 - 内存系统的重排序  
    由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。下面是指令重排序顺序图：
    
 ![Alt 指令重排序顺序图](https://github.com/YuanLicc/concurrent-notes/blob/master/doc/images/InstructionReOrder.png)
 
&#8194;&#8194;&#8194;&#8194;后面两个重排序均为处理器的重排序。这些重排序可能导致多线程程序出现呢内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。
 
 #### 并发编程模型的分类
 
 &#8194;&#8194;&#8194;&#8194;现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲弄去，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读写操作的执行顺序，不一定与内存实际发生的读写操作顺序一致。前面的叙述简易的说就是在处理器对内存的写操作之间加了个写缓冲区，也就是处理器首先将写入值存入写缓冲区，这可能造成写入写缓冲区后还没写入内存就执行对内存的读取。为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类：
 
 <table>
    <tr>
      <td>屏障类型</td>
      <td>指令示例</td>
      <td>说明</td>
    </tr>
    <tr>
      <td>LoadLoad Barriers</td>
      <td>Load1; LoadLoad; Load2</td>
      <td>确保Load1数据的装载先于Load2及所有后续装载指令的装载</td>
    </tr>
    <tr>
      <td>StoreStore Barriers</td>
      <td>Store1; StoreStore; Store2</td>
      <td>确保Store1数据对其他处理器可见（刷新到内存）先于Store2及所有后续存储指令的存储</td>
   </tr>
    <tr>
      <td>LoadStore Barriers</td>
      <td>Load1; LoadStore; Store2</td>
      <td>确保Load1数据的装载先于Store2及所有后续存储指令的装载</td>
    </tr>
    <tr>
      <td>StoreLoad Barriers</td>
      <td>Store1; StoreLoad; Load2</td>
      <td>确保Store1数据对其他处理器变得可见（刷新到内存）先于Load2
      及所有后续装载指令的装载。StoreLoad 
      Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令</td>
    </tr>
 </table>
 
&#8194;&#8194;&#8194;&#8194;StoreLoad Barriers是一个全能型的屏障，他同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把缓冲区的数据全部刷新到内存中。
 
 #### happens-before
 
&#8194;&#8194;&#8194;&#8194;从JDK 5开始，Java使用新的JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果对另一个操作可见，那么两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是不同线程之间。happens-before规则如下：
 
 - 程序顺序规则  
    一个线程中的每个操作，happens-before于该线程中的任意后续操作。
    
 - 监视器锁规则  
    对一个锁的解锁，happens-before于随后对这个锁的加锁。
    
 - volatile变量规则  
    对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
 
 - 传递性  
    如果A happens-before B，且B happens-before C，那么A happens-before C。
 
 **注意**  
&#8194;&#8194;&#8194;&#8194;两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行，happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

#### 重排序

&#8194;&#8194;&#8194;&#8194;重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。

##### 数据依赖性

&#8194;&#8194;&#8194;&#8194;
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间存在数据依赖性。数据依赖分为下列三种类型：

- 写后读  
&#8194;&#8194;&#8194;&#8194;写一个变量之后，在读这个变量``a = 1; b = a;``
    
- 写后写  
&#8194;&#8194;&#8194;&#8194;写一个变量之后，再写这个变量``a = 1; a = 2;``

- 读后写  
&#8194;&#8194;&#8194;&#8194;读一个变量之后，再写这个变量``a = b; b = 2;``

&#8194;&#8194;&#8194;&#8194;可见上面的情况中，重排序会影响执行结果。前面提到，编译器和处理器可能对操作进行重排序，但它们在进行重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。这里的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作哦，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。

##### as-if-serial语义

&#8194;&#8194;&#8194;&#8194;as-if-serial语义的意思：不管怎么重排序（编译器和处理器为了提高并行速度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。为了遵守as-if-serial语义，编译器和处理器不会对存在数据以来的操作重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。如 ``int a = 1; int b = 3; int c = a + b;``，c依赖于a、b，但是a、b不互相依赖，就可能进行重排序，所以可能有两种执行顺序。对于单线程而言，as-if-serial语义保证了程序达到预期结果。
 
 ##### 程序顺序规则
 
&#8194;&#8194;&#8194;&#8194;
根据happens-before的程序顺序规则，前面的例子存在3个happens-before关系：

- a happens-before b

- b happens-before c

- a happens-before c

&#8194;&#8194;&#8194;&#8194;第三条是根据传递性推导出来的，a happens-before b，实际执行可能对a、b进行重排序，前面说过happens-before不要求前一个操作一定在后一个操作之前执行，JMM仅仅要求前一个操作对后一个操作可见，且前一个操作按顺序排在第二个操作之前，这个操作a的执行结果不需要对操作b可见，且两者重排序后执行结果与不进行重排序执行结果一致，所以JMM认为这种重排序不是非法的，允许这种重排序。

##### 重排序对多线程的影响

&#8194;&#8194;&#8194;&#8194;前面我们看到重排序在单线程中不影响执行结果，但是在多线程中若多个线程对同一个变量进行操作时，就需要考虑重排序对程序带来的影响了。

``` Java
int a = 0;
boolean mark = false;

void write() {
    a = 1;
    mark = true;
}

void validate() {
    if(mark) {
        int b = a * a;
        system.out.println(b);
    }
}
```
&#8194;&#8194;&#8194;&#8194;
很显然，上面的write方法是对a的写，并利用mark来标识a是否被写，然后validate方法验证a
是否被写并执行一个a*a的操作，假设线程A执行write方法，然后线程B执行validate方法，会出现以下两种影响：

- `a = 1` 操作与`mark = true`操作没有数据依赖，进行重排序，先执行`mark = 
true`，此时线程B读到mark，判断为真，执行下一步操作，若此时变量a任然为0，则语义被重排序破坏，若此时a
已经为1，那么重排序并没有破坏语义。

- 判断`if(mark)`操作与`int b = a * a`操作存在控制依赖，当存在控制依赖时，会影响指令序列的并行度。为此，编译器核处理器会采用猜测执行来客服控制小惯性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算`a * a`，然后把计算结果临时保存到一个名为重排序缓冲的硬件缓存中。当控制为真时，将计算结果写入变量b中，那就会出现a任然为0的情况下进行计算，直到mark为真时，将计算结果赋给b，造成语义被破坏。单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果，这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因。

#### 顺序一致性

&#8194;&#8194;&#8194;&#8194;顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参考。

##### 数据竞争与顺序一致性

&#8194;&#8194;&#8194;&#8194;
当程序为正确同步时，就可能会存在数据竞争。Java内存模型规范对数据竞争的定义如下：在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。  
&#8194;&#8194;&#8194;&#8194;当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。JMM对正确同步的多线程程序的内存一致性做了如下保证：

- 如果程序是正确同步的，程序的执行将具有顺序一致性（即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。

##### 顺序一致性内存模型

&#8194;&#8194;&#8194;&#8194;顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性：

- 一个线程中的所有操作必须按照程序的顺序来执行。

- （不管线程是否同步
）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。

&#8194;&#8194;&#8194;&#8194;在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每个线程必须按照程序的顺序来执行内存读写操作。任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，会把所有线程的所有内存读写操作串行化（即在顺序一致性模型中，所有操作之间具有全序关系）。从另一角度来讲，不管是同步还是未同步的程序，在多线程并发执行的情况下，都会有一个执行顺序，每个线程都能看到一个相同的执行顺序，原因是顺序一致性内存模型中的每个操作必须立即对任意线程可见。但是JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其他线程看到的操作顺序将不一致。

##### 同步程序的顺序一致性效果

&#8194;&#8194;&#8194;&#8194;还是之前的例子，现在使用锁来进行同步：

``` Java
int a = 0;
boolean mark = false;

synchronized void write() {
    a = 1;
    mark = true;
}

synchronized void validate() {
    if(mark) {
        int b = a * a;
        system.out.println(b);
    }
}
```

&#8194;&#8194;&#8194;&#8194;根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码逸出到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图。JMM在具体实现上的基本方针为：在不改变程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。

##### 未同步程序的执行特性

&#8194;&#8194;&#8194;&#8194;对于未同步或为正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值，JMM保证线程读操作读取到的值不会无中生有。为了实现最小安全性，JMM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在已清零的内存空间分配对象时，域的默认初始化已经完成了。JMM不保证未同步程序的执行结果与改程序在顺序一致性模型中的执行结果一致。因为如果想要保证执行结果一致，JMM需要进制大量的处理器和编译器的优化，这对程序的执行性能会产生很大的影响。而且未同步程序在顺序一致性模型中执行时，整体是无序的，其执行结果往往无法预知。未同步程序在这两个模型的执行特性有如下差异：

- 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行。

- 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。

- JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读写操作都具有原子性。

&#8194;&#8194;&#8194;&#8194;第三个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务。总线事务包括读事务和写事务。读事务从内存传递数据到处理器，写事务从处理器传送数据到内存，每个事务会读写内存中的一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它的处理器和IO设备执行内存的读写。

**总线工作机制**  
&#8194;&#8194;&#8194;&#8194;若多个处理器同时向总线发起总线事务，这时总线仲裁会对竞争做出裁决，总线仲裁会确保所有处理器都能公平的访问内存，假设处理器A获胜，它可以进行总线事务，而其他处理器则要等待处理器A的总线事务完成后才能再次执行内存访问。若在处理器A执行总线事务期间，另外的处理器发起了总线事务，此处理器的请求会被总线禁止。

&#8194;&#8194;&#8194;&#8194;在一些32位的处理器上，如果要求对64位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，Java语言规范孤立但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行。这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。

#### volatile的内存语义

##### volatile的特性

&#8194;&#8194;&#8194;&#8194;理解volatile特性可以把对volatile的单个的读或者写，看成是使用同一个锁对单个读或者写操作做了同步（注意，单个读或者写意思为要么是读，要么是写，请区别于读写操作）。锁的语义决定了临界区代码的执行具有原子性，这意味着，即使是64位的long、double性变量，只要是volatile变量，读或者写就具有原子性。而复合操作如++，这类操作不具有原子性。volatile特性如下：

- 可见性，对一个volatile变量的读，总是能看到对这个变量最后的写入。

- 原子性，对任意单个volatile变量的单个读或者写操作具有原子性，复合操作不具有原子性。

&#8194;&#8194;&#8194;&#8194;从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile的读与锁的获取有相同的内存语义。

##### volatile内存语义实现

&#8194;&#8194;&#8194;&#8194;为了实现volatile的内存语义，JMM分别限制了编译器重排序、处理器重排序。volatile重排序的限制如下表：

<table align="center">
    <tr>
        <td>是否能重排序</td>
        <td colspan="3">第二个操作</td>
    </tr>
    <tr>
        <td>第一个操作</td>
        <td>普通变量的读/写</td>
        <td>volatile变量的读取</td>
        <td>volatile变量的写入</td>
   </tr>
   <tr>
        <td>普通变量的读/写</td>
        <td>是</td>
        <td>是</td>
        <td>否</td>
   </tr>
   <tr>
        <td>volatile变量的读取</td>
        <td>否</td>
        <td>否</td>
        <td>否</td>
   </tr>
   <tr>
        <td>volatile变量的写入</td>
        <td>是</td>
        <td>否</td>
        <td>否</td>
   </tr>
</table>

&#8194;&#8194;&#8194;&#8194;表格的意思是，第一个操作与第二个操作是否允许进行重排序。为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：

- 在每个volatile变量写操作的前面插入一个StoreStore屏障。

- 在每个volatile变量写操作的后面插入一个StoreLoad屏障。

- 在每个volatile变量读操作的后面插入一个LoadLoad屏障。

- 在每个volatile变量读操作的后面插入一个LoadStore屏障。

&#8194;&#8194;&#8194;&#8194;上诉策略保证了任意程序，任意平台下都能得到正确的volatile内存语义。由于不同处理器有不同松紧度的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型进行优化，比如省略部分屏障。

#### 锁的内存语义

&#8194;&#8194;&#8194;&#8194;锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。当现线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。下面以重入锁（ReentrantLock）的例子来解析锁的实现：

``` Java
ReetrantLock lock = new ReetrantLock();
public void A() {
   lock.lock();
   try{
        //...
   }
   finally{
        lock.unlock();
   }
}
```

&#8194;&#8194;&#8194;&#8194;在ReentrantLock中通过lock()方法获取锁；unlock()方法释放锁。ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（暂时简称AQS）。AQS使用一个整型的volatile变量（state）来维护同步状态。ReentrantLock中公平锁具体代码如下：

``` Java
    final void lock() {
        acquire(1);
    }

    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
```

&#8194;&#8194;&#8194;&#8194;其中lock()方法调用acquire(1)再到tryAcquire(1)，接着会看到获取前面说到的volatile变量赋给c，对volatile变量的操作可以避免重排序，接着进行一系列的判断，其中compareAndSetState(0, acquires)方法目的是将值为0的state利用CAS交换为acquire（也就是1），交换成功，则获取到了锁，对于CAS的具体实现，代码为c++，使用的内嵌的汇编语言实现，也就是cmpxchg（比较并交换CAS）等一系列指令，程序也会根据当前处理器的类型来决定是否为cmpxchg指令叫上lock前缀。若程序在多处理器上运行，则加上lock前缀，否则省略（但处理器能维护但处理器内的顺序一致性）。

##### concurrent包的实现

Java的CAS
使用处理器上提供的搞笑机器级别的原子指令，这些原子指令以原子方式对内存执行读改写操作，这是在多处理器中实现同步的关键。同时，volatile变量的读写和CAS可以实现线程之间的通信。这些内容就是concurrent包实现的基石。结合前面的例子，总结出一个通用的同步实现方式：

1. 声明共享变量为volatile

2. 使用CAS的原子条件更新来实现线程间的同步

3. 配合以volatile的读、写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。

AQS及非阻塞数据结构可原子变量类，这些concurrent
包中的基础类都是使用这种方式实现的，concurrent包实现示意图如下：

[Alt concurrent包实现示意图](https://github.com/YuanLicc/concurrent-notes/blob/master/doc/images/concurrent.png)

#### final域的内存语义

